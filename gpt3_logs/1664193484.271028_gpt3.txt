The following is an unstructured video transcript by David Shapiro. Please rewrite this as a more structured, clear essay.

TRANSCRIPT: that's exactly why we need to freeze it uh just like you bring up newton with all his laws never changed einstein only added the addendum that you forgot time so e every action has an opposite reaction at the speed at which time occurs is what einstein added to sir isaac newton so that's an example of where freezing is very beneficial and then making addendums to it and yet not making the entire thing fall apart so yeah that's an example of where freezing is the most important all right maybe it was a bad example from event or good example i guess yeah all right thanks great um let's see andy and annie i think um who i think any was waiting first if you want to jump back in about law so essentially all these questions you have liability have been already been discussed and for example in the use of models like um the the data that is the mothers are trained by like for example the tech text mining or the image uh mining that for example daily2 uses it it's all been recognized as fair use for example and there's the question about the ability from a penal perspective if similar you know that there's physical persons and they are legal persons and similarly to ai similarly to companies cannot be sued penally or yes in the civil way but the the people the company itself is not responsible it's the directors is how they a company's structure in their in their constitutive act and those people are responsible so it's similar to ai that is the case and also it's a case of strict liability in the sense like similarly to tutors to their children parents or children like if your children come into crime or makes a something civil damages etc it's the tutor that is responsible regardless if they had nothing to do with it or they were responsible etc in the case of open ai they they for that reason they make the the use of gbt3 only exclusive to certain types of people until they make it public and they are doing the same thing now with delhi too i'm trying to rebuild all the materials i had during discussions of the the classes of ai and law i'm happy to share with you guys um but i don't i don't know if if ai will ever achieve the same status as a human being in regards of the of the law even animals don't have known animal they have a very very few laws up applicable to them so um i don't know how they will achieve also right now for example in copyright um the the people cannot that did the models can make use of the copyright but not humans yet like ai no matter if if ascension ai comes now or wants to copyright the one of these achievements it can do so and so there's like tons of things but that's what i wanted to say so i actually i looked into this a uh copywriting also requires a last name so like uh the queen of england uh elizabeth she cannot file a copyright legally there's quite a few rules about copywriting that a company can file a copyright so if the ai was managing a company and the people recognized it that the ai could autonomously then fire up file a copyright for the company would be one way would legally work within a system right now but i've never seen ai invent anything so um because we've never seen ai invent anything uh it just sorts through information and figures out holes more or less it the people that own the copyright are the people who set up that ai to do that behavior are the ones who usually would ones be who control that copyright ultimately uh but if we had an autonomous ai of course things might change but if you read the copyright laws i don't think they actually would because i think the copyright laws actually already cover that but that's a whole other conversation excellent thanks for that um that perspective um as a professionally trained lawyer again it's just incredible to get all these different perspectives um andy i think you've been waiting patiently to jump back in you know i was about the on the issue of liability i just could offer the example of lexi um because i think it's instructive so so lexi's a legal chatbot i have it on the internet um and uh it keeps me up at night for a couple of reasons um one is you know will it go wrong and provide legal advice now carefully trained it not to provide legal advice but let's suppose a scenario where it did um and it tells somebody something um you know that that leads to a bad legal outcome so who would be responsible for that well setting aside the the law for a second and just thinking about it ethically um you know i charging battery myself to be primarily responsible as the uh person who kind of put this bot together and put it out into the world i am i am taking responsibility for it and with that unless i had gone to the trouble of creating this bot um probably people wouldn't have uh run into it right uh and so i am i'm sort of taking i think the analogy be something like power so imagine you have like a power station that's run by the power company or power generator that's run by a power company um and then that power then runs from the power company to a house and if i install that power in a not good way and it blows up your house and it hurts you who's responsible is it the power company or is it me well it's probably me right on the other hand what if uh you can imagine an analogy um like what if the power company screwed something up and it surged and it came that came through and blew up blew up the house well then you could imagine the power company being level so i think there's like a stream and downstream thing here that um that is happening so that kind of the last mile integrator which in this case would be me is i would imagine primarily responsible at least for the foreseeable future and then of course upstream of that if gbt3 if you know sam altman does something really horrible and and now all of a sudden my bot just starts spitting out massively racist bs or something like that well that's probably not on me either so anyway that's how i would think about liability that's

CLEAR ESSAY:

==========

In discussing the freezing of AI, it is important to consider the example of Newton and Einstein. Newton's laws never changed, but Einstein added the idea of time to them. This example demonstrates how freezing can be beneficial in adding new ideas while still maintaining the structure of the original laws.

Similarly, in the legal realm, companies cannot be sued penalistically, but the people who run the company are held responsible. This is similar to how AI cannot be sued, but the people who created it can be held responsible for its actions. Additionally, copyright law currently prohibits humans from copyrighting anything created by AI, but this may change in the future as AI becomes more autonomous.

Ultimately, it is difficult to say whether or not AI will ever achieve the same status as a human being in terms of legal responsibility. However, the current legal system is set up in a way that suggests that the people who create and run AI will be held primarily responsible for its actions.